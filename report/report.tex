\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[T2A]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[left=30mm, right=15mm, top=20mm, bottom=20mm]{geometry}
\usepackage{listings} % for code snippets
\usepackage{float}

% \newcommand{\high}[1]{\texttt{#1}}
\newcommand{\img}[2]{
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{#1}
        \caption{#2}
    \end{figure}
}
% \usepackage[fencedCode,inlineFootnotes,citations,definitionLists,hashEnumerators,smartEllipses,hybrid]{markdown}


% No indentation for paragraphs
\setlength\parindent{0pt}

\begin{document}
\begin{titlepage}
\begin{center}
    Московский государственный университет имени М. В. Ломоносова

    \bigskip
    \includegraphics[width=50mm]{msu.eps}

    \bigskip
    Факультет Вычислительной Математики и Кибернетики\\
    Кафедра Cуперкомпьютеров и Квантовой Информатики\\[10mm]

    \textsf{\large\bfseries
        КУРСОВАЯ РАБОТА СТУДЕНТА 323 ГРУППЫ\\[10mm]
        Исследование применимости алгоритма дифференциальной эволюции для процесса обучения нейронной сети
    }\\[10mm]

    \begin{flushright}
        \parbox{0.5\textwidth}{
            Выполнил:\\
            студент 3 курса 323 группы\\
            \emph{Бобко Никита Александрович}\\[5mm]
            Научный руководитель:\\
            доцент  кандидат физ.-мат. наук\\
            \emph{Попова Нина Николаевна}
        }
    \end{flushright}

    \vspace{\fill}
    Москва, 2019
\end{center}
\end{titlepage}

\newpage
\tableofcontents
\newpage

\section{Введение}
    Нейронные сети являются очень популярным инструментом анализа данных в последнее время, особенно, когда речь заходит о задачах классификации изображений, анализа человеческой речи и ее распознавания. Это те проблемы, в которых нам бы хотелось, чтобы компьютеры показывали поведение, похожее на человеческое. Нейронные сети, а особенно сверточные, хорошо себя показали в решении такого рода проблем. \\

    Поэтому эффективное обучение нейронных сетей в наше время считается актуальной проблемой, которая обычно сопровождается сложными вычислениями. Алгоритм дифференциальной эволюции зарекомендовал себя как эффективный эвристический алгоритм поиска глобального минимума. \\
    
    Цель настоящей работы исследовать потенциал алгоритма дифференциальной эволюции для процесса обучения нейронных сетей. 

\section{Обзор других работ}
    В этом разделе приведем обзор других работ, которые ведутся в данном направлении. В частности можно взглянуть на работу Uber AI labs \cite{uber}, на основе кодовой базы которой выполнена текущая работа. \\

    В своей работе Uber AI labs исследует потенциал обучения нейронной сети, которая учиться играть в Atari Frostbite и пытается обучить 3-х мерную модель гуманоида ходить. Обучают они нейронную сеть с помощью различных эволюционных алгоритмов, таких как генетический 

\section{Постановка задачи}
    Постановка задачи формулируется следующим образом: разработать алгоритм дифференциальной эволюции и попробовать обучить нейронную сеть, так чтобы она набирала как можно большее количество очков в игре Atari Frostbite.

    \subsection{Правила игры Atari Frostbite}
    Нижнии $2/3$ экрана заполнены водой с четыремя рядами ледяных глыб плывущих в горизонтальном направлении. Игрок делает свои ходы прыгая с одного ряда на другой, пытаясь избежать различных противников в виде крабов и птиц. Также есть рыбы, которые дают дополнительные очки. \\

    В верхней части экрана находится побережье, где игрок должен построить иглу. Каждый раз, когда игрок прыгает на глыбу, ряд, в котором находится глыба, меняет цвет с белого на голубой и иглу строится на $+1$ ледяной блок. После того, как игрок пропрыгал все ряды глыб на экране (напоминаем у нас всего 4 ряда ледяных глыб), то все глыбы обратно меняют цвет с голубого на белый и игрок может начать заново прыгать по глыбам. \\

    После того, как все 15 ледяных блоков, необходимых для построения иглу, собраны, игрок должен вернуться обратно на побережье и войти в иглу, это переведет игрока на следующий уровень. На каждом уровне враги и ледяные блоки двигаются быстрее чем на предыдущем уровне, тем самым усложняя игру. \\

    Каждый из уровней обязан быть закончен не более чем за $45$ секунд, иначе игрок умирает от холода. Чем быстрее закончен уровень, тем больше дополнительных очков начисляется игроку.

\section{Метод решения задачи}
    В качестве метода решения выбран алгоритм дифференциальной эволюции. Этот алгоритм принадлежит к классу стахостических алгоритмов минимизации произвольной функции, не требующий знания градиента этой функции, что делает этот алгоритм очень удобным для применения в ряде задач.

    \subsection{Алгоритм дифференциальной эволюции}
        Алгоритм дифференциальной эволюции был разработан Рэйнером Сторном и Кеннетом Прайсом, впервые опубликован ими в 1995 году \cite{DE-1995}. Из интересного также можно отметить, что этому алгоритму удалось занять 3-е место в <<First International Contest on Evolutionary Computation>> (1stICEO), который проходил в Нагое, мае 1996 \cite{DE}. \\

        Формально, пусть имеем $f: \mathbb{R}^{n} \to \mathbb{R}$ - функция, которую требуется минимизировать (заметим, что максимизация может быть выполнена рассмотрением функции $h = -f$). Градиент $f$ не извесен. Цель: найти решение $m$, для которого $f(m) \leq f(p)$ для любого $p$ в области определения, что означает, что $m$ является глобальным минимумом. \\

        У алгоритма дифференциальной эволюции есть два настраиваемых параметра: \\ 
        $P \in [0, 1]$ - <<вероятность скрещевания>> \\
        $F \in [0, 2]$ - некоторый весовой коэффициент \\

        Популяцией будем называть некоторое конечное множество $\{~x~|~x \in \mathbb{R}^n~\}$. \\

        Пусть $x \in \mathbb{R}^n$ один из кандидатов на решение в популяции. Тогда алгоритм дифференциальной эволюции будет выглядеть следующим образом \cite{params-for-de}:

        \begin{itemize}
            \item[-] Проинициализировать все $x$ случайными значениями в области поиска минимума $f$
            \item[-] До тех пор пока критерий остановки не выполнен (критерием остановки могут быть различные значения, такие как: число итераций, допустимое значение функции $f$,~...)
            \begin{itemize}
                \item[-] Для каждого $x$ из популяции выполнить:
                \begin{itemize}
                    \item[-] Выбрать 3 случайных $a$, $b$ и $c$ из популяции, они должны быть отличны друг от друга, а также от $x$
                    \item[-] Выбрать случайное число $R \in \{1, ..., n\}$
                    \item[-] Сгенерировать вектор $y \in \mathbb{R}^n$ следующим образом: Пусть $r_i \sim U(0, 1)$ - случайная величина с равномерным распределением. Если $r_i < P \times R$ или $i = R$, то $y_i = a_i + F \times (b_i - c_i)$, иначе $y_i = x_i$
                    \item[-] Если оказалось, что $f(y) < f(x)$, то заменить в популяции $x$ на $y$
                \end{itemize}
            \end{itemize}
        \end{itemize}

        \subsection{Архитектура нейронной сети}
            Игра представляет из себя $3$-х мерную матрицу размерности $160 \times 210 \times 3$ (Игра имеет разрешение $160 \times 210$ и еще одно одно измерение размерностью $3$ для RGB). Прежде чем дать это изображение на вход нейронной сети каждый кадр уменьшается до размеров $84 \times 84$ пикселей и конвертируется из цветного изображения в изображения в градациях серого. Дальше 4 последовательных кадра <<склеиваются>> и получается $3$-х мерная матрица размерности $84 \times 84 \times 4$, которая уже подается на вход нейронной сети. \\

            Архитектура нейронной сети выглядит следующим образом:
            \begin{itemize}
                \item $84 \times 84 \times 4$ входных нейрона
                \item Сверточный слой с 16 фильтрами, размером ядра $8 \times 8$ и шагом 4
                \item Сверточный слой с 32 фильтрами, размером ядра $4 \times 4$ и шагом 2
                \item Выравнивающий слой (flatten layer)
                \item Полносвязный слой с 256 выходами
                \item Полносвязный слой с числом выходов равным количеству действий, которые можно делать в игре Atari Frostbite
            \end{itemize}

            Такая архитектура была выбрана основываясь на \cite{uber}.

    \subsection{Как происходит обучение и взаимодействие алгоритма дифференциальной эволюции с нейронной сетью}
        Так как в алгоритме дифференциальной эволюции в общем случае идет минимизация некоторой функции $f(x)$, где $x \in \mathbb{R}^n$, то надо надо выбрать функцию $f$ и установить биективное отображение между весами нейронной сети и простанством $\mathbb{R}^n$. \\

        В качестве функции $f$ выбрана функция равная количеству очков, которое набирает нейронная сеть в игре Atari Frostbite за фиксированое время (если в течении этого времени нейроная сеть успела проиграть, то считаем то количество очков, которое она успела набрать до проигрыша). В нашем случае это число равно $5000$ итераций взаимодействия с библиотекой gym (именно эта библиотека используется для эмуляции игры Atari Frostbite). Это число выбрано таким образом, чтобы быть достаточно большим, чтобы количество очков, которое можно набрать не ограничевалось сверху временем, но и не таким большим, чтобы вычисление $f$ занимало слишком много времени. \\

        Таким образом, осталось только установить биективное соответствие между $\mathbb{R}^n$ и весами нейронной сети. Это делается тривиальным образом, просто методом упорядовачивания весов нейроной сети. Сеть имеет $n=1009058$ параметров для обучения. \\

        В качестве значений параметров $P$, $F$ алгоритма дифференциальной эволюции были выбраны $0.9$ и $0.5$ соответственно.

\section{Вычислительный эксперимент предложенного алгоритма}
    Вычислительный эксперимент проводился на платформе \href{https://cloud.google.com/}{Google Cloud}. На следующих характеристиках: \\

    Процессор: Intel(R) Xeon(R) CPU \\
    Число физических ядер: 12 \\
    Число виртуальных ядер: 24 \\
    Частота: 2 Ггц \\
    ОЗУ: 90 ГБ \\

    Все результаты вычислительного эксперимента алгоритма дифференциальной эволюции (DE) ниже приведины в сравнении с алгоритмом~ES из работы Uber AI labs \cite{uber}.
    \img{score_plot.png}{Зависимость количества набираемых очков от поколения}

    \img{time_plot.png}{Зависимость времени обучения от поколения}

    Видео того, как работает обученная нейронная сеть, можно найти по адресу: \\
    \url{https://www.youtube.com/watch?v=VjWcr3XTsHU&feature=youtu.be}

\section{Описание программной реализации}
    Программная реализация построена на базе \\
    \url{https://github.com/uber-research/deep-neuroevolution}. \\
    Мою программную реализацию можно найти по адресу \\
    \url{https://github.com/nikitabobko/deep-neuroevolution}. \\
    Программа выполнена на языке Python~3.\\

    Основные модули и их описание:
    \begin{itemize}
        \item \verb!es_distributed/policies.py! содержит класс \verb!Policy! и его наследника \verb!ESAtariPolicy!. В этих классах реализованы политики обсчета нейронной сети и сама структура нейронной сети
        \item \verb!es_distributed/dist.py! содержит два класса \verb!CoolWorkerClient! и \verb!CoolMasterClient!. Это классы в которых описано взаимодействие основного процесса и процессов-рабочих. Взаимодействие сделано через пересылки сообщений по сокетам по TCP соединению. (процесс-мастер запускается по адресу \verb!127.0.0.1:9999!)
        \item \verb!es_distributed/es.py! содержит две основные функции \verb!run_master! и \verb!run_worker!, которые выполняют процесс-мастер и процессы-рабочие соответственно.
        \item \verb\scripts/viz.py\ визуализирует файл сохраненный на $i$-ой итерации, чтобы можно было вживую увидеть то, как играет лучший индивид из поколения.
    \end{itemize}

    Программная реализация выглядит следующим образом: сначала запускается вышеупомянутый bash скрипт \verb!scripts/local_run_exp.sh!. В этом скрипте можно указать количество рабочих. Далее этот скрипт запускает функцию \verb!es_distributed.main.master!, в которой происходит fork всех дочерних процессов и поднимается сервер, через который в последствии будет идти общение мастера и рабочих. \\

    Далее мастер итерация за итерацией будет выполнять \verb!es_distributed.es.run_master!, где происходит алгоритм дифференциальной эволюции. Рабочим же распределяются задачи по подсчету количества очков, которые набирает отдельно взятый индивид из популяции. \\

    Диаграмма UML, описанной реализации, выглядит следующим образом:
    \img{uml.png}{UML диаграмма реализации}

    Мастер использует \verb!ESAtariPolicy! для того, чтобы в него присваивать лучшего на данной итерации индивида из популяции и потом на каждой итерации сохранять его веса в отдельный файл. Этот файл можно позже запустить в режими визуализации, чтобы увидеть, как обученная нейронная сеть играет вживую.

    \subsection{Установка и запуск}
    После того, как проект склонирован с помощью git: \\

    \verb!git clone https://github.com/nikitabobko/deep-neuroevolution.git! \\

    Нужно создать виртуальную среду Python 3 и активировать ее: \\

    \verb!python3 -m venv env! \\
    \verb!. env/bin/activate! \\

    Далее идет установка необходимых зависимостей: \\

    \verb!pip install -r requirements.txt! \\

    И после этого можно запустить процесс обучения: \\

    \verb!. scripts/local_run_exp.sh es configurations/frostbite_es.json! \\

    Чтобы запустить режим визуализации нужно выполнить: \\

    \verb!python -m scripts.viz 'FrostbiteNoFrameskip-v4' <YOUR_H5_FILE>!

\section{Заключение}
    Как можно заметить алгоритм дифференциальной эволюции неплохо показал себя в решении поставленной задачи. Он оказался точно лучше алгоритма ES в \cite{uber}. Тем не менее пока не ясен его потенциал при увеличении числа поколений. \\

    Также в качестве направления дальнейшей работы интересно было исследовать эффективность обучения при различных выборах значений параметров алгоритма дифференциальной эволюции $P$ и $F$. Таким образом в \cite{DE} утверждается, что выбор параметра $F$ для каждого поколения случайным образом значительно улучшает сходимость алгоритма.

\newpage
\addcontentsline{toc}{section}{Список литературы}
\begin{thebibliography}{}
    \bibitem{uber}
    \emph{Edoardo Conti, Vashisht Madhavan, Felipe Petroski Such, Joel Lehman, Kenneth O. Stanley, Jeff Clune}.
    Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents \\
    \url{https://arxiv.org/abs/1712.06560}
    
    \bibitem{DE-1995}
    \emph{Rainer Storn, Kenneth Price}. Differential Evolution - a simple and efficient adaptive scheme for global optimization over continuous spaces \\
    \url{http://web.archive.org/web/20050424071310/http://www.icsi.berkeley.edu/techreports/1995.abstracts/tr-95-012.html}

    \bibitem{ConvolutionInetGuide}
    A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way

    \bibitem{LiuLiu}
    Liu G. R., Liu M. B. Smoothed particle hydrodynamics: a meshfree particle method. --- Singapore : World Scientific Publishing. --- 2003. --- 449 p.

    \bibitem{DE}
    Differential Evolution (DE) for Continuous Function Optimization (an algorithm by Kenneth Price and Rainer Storn) \\
    \url{http://www1.icsi.berkeley.edu/\%7Estorn/code.html}

    \bibitem{params-for-de}
    \emph{Magnus Erik Hvass Pedersen}. Good Parameters for Differential Evolution \\
    \url{https://pdfs.semanticscholar.org/48aa/36e1496c56904f9f6dfc15323e0c45e34a4c.pdf}

    % \bibitem{batch}
    % \emph{Sergey Ioffe, Christian Szegedy}. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift \\
    % \url{https://arxiv.org/abs/1502.03167}

\end{thebibliography}

\end{document}
